{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f40ed66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fa8e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"App\") \\\n",
    "    .master(\"spark://master:7077\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.cores\", \"3\") \\\n",
    "    .config(\"spark.executor.instances\", \"4\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"100\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.files.ignoreCorruptFiles\", \"true\")\n",
    "spark.conf.set(\"spark.sql.files.ignoreMissingFiles\", \"true\")# total across executors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d6e1198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "SPARK_UI = \"http://192.168.56.102:4040\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5f31a9",
   "metadata": {},
   "source": [
    "## Von hdfs lesen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19e7d9b-0e6d-4269-9057-7cf2a2cee7d9",
   "metadata": {},
   "source": [
    "10 Wiederholungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa0b82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: 10 braucht 0.12 Sekunden\n",
      "Job ID: 11 braucht 0.14 Sekunden\n",
      "Job ID: 12 braucht 0.14 Sekunden\n",
      "Job ID: 13 braucht 0.16 Sekunden\n",
      "Job ID: 14 braucht 0.14 Sekunden\n",
      "Job ID: 15 braucht 0.12 Sekunden\n",
      "Job ID: 16 braucht 0.11 Sekunden\n",
      "Job ID: 17 braucht 0.07 Sekunden\n",
      "Job ID: 18 braucht 0.08 Sekunden\n",
      "Job ID: 19 braucht 0.12 Sekunden\n",
      "[0.122, 0.138, 0.14, 0.163, 0.143, 0.115, 0.107, 0.07, 0.084, 0.125]\n",
      "Zeit für die Ausführung der Zelle: 2.90 seconds\n",
      "Mittelwert aller Spark Jobs: 0.12 seconds\n",
      "Median aller Spark Jobs: 0.12 seconds\n",
      "Sdt aller Spark Jobs: 0.03 seconds\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "listh10 = []\n",
    "\n",
    "start_all = time.time()\n",
    "for i in range(10):\n",
    "    dfrh= spark.read.parquet(\"hdfs:///input/parquet\")\n",
    "    app_id = requests.get(f\"{SPARK_UI}/api/v1/applications\").json()[0][\"id\"]\n",
    "    job = requests.get(f\"{SPARK_UI}/api/v1/applications/{app_id}/jobs\").json()[0]\n",
    "    start = datetime.fromisoformat(job[\"submissionTime\"].replace(\"GMT\", \"+00:00\"))\n",
    "    end = datetime.fromisoformat(job[\"completionTime\"].replace(\"GMT\", \"+00:00\"))\n",
    "    timer = (end - start).total_seconds()\n",
    "    job_info = requests.get(f\"{SPARK_UI}/api/v1/applications/{app_id}/jobs\").json()\n",
    "    latest_job = sorted(job_info, key=lambda j: j[\"submissionTime\"], reverse=True)[0]\n",
    "    listh10.append(timer)\n",
    "    print(f\"Job ID: {latest_job['jobId']} braucht {timer:.2f} Sekunden\")\n",
    "end_all = time.time() \n",
    "\n",
    "print(listh10)\n",
    "print(f\"Zeit für die Ausführung der Zelle: {end_all - start_all:.2f} seconds\")\n",
    "print(f\"Mittelwert aller Spark Jobs: {np.mean(listh10):.2f} seconds\")\n",
    "print(f\"Median aller Spark Jobs: {np.median(listh10):.2f} seconds\")\n",
    "print(f\"Sdt aller Spark Jobs: {np.std(listh10):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778814b3-5527-490d-88d3-d295a83f9b00",
   "metadata": {},
   "source": [
    "100 Wiederholungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95b67bb6-7a93-4f89-b719-68267851eba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: 20 took 0.11 seconds\n",
      "Job ID: 21 took 0.11 seconds\n",
      "Job ID: 22 took 0.15 seconds\n",
      "Job ID: 23 took 0.10 seconds\n",
      "Job ID: 24 took 0.17 seconds\n",
      "Job ID: 25 took 0.13 seconds\n",
      "Job ID: 26 took 0.13 seconds\n",
      "Job ID: 27 took 0.09 seconds\n",
      "Job ID: 28 took 0.10 seconds\n",
      "Job ID: 29 took 0.09 seconds\n",
      "Job ID: 30 took 0.11 seconds\n",
      "Job ID: 31 took 0.09 seconds\n",
      "Job ID: 32 took 0.07 seconds\n",
      "Job ID: 33 took 0.14 seconds\n",
      "Job ID: 34 took 0.15 seconds\n",
      "Job ID: 35 took 0.14 seconds\n",
      "Job ID: 36 took 0.14 seconds\n",
      "Job ID: 37 took 0.15 seconds\n",
      "Job ID: 38 took 0.18 seconds\n",
      "Job ID: 39 took 0.12 seconds\n",
      "Job ID: 40 took 0.28 seconds\n",
      "Job ID: 41 took 0.09 seconds\n",
      "Job ID: 42 took 0.11 seconds\n",
      "Job ID: 43 took 0.08 seconds\n",
      "Job ID: 44 took 0.09 seconds\n",
      "Job ID: 45 took 0.14 seconds\n",
      "Job ID: 46 took 0.13 seconds\n",
      "Job ID: 47 took 0.14 seconds\n",
      "Job ID: 48 took 0.12 seconds\n",
      "Job ID: 49 took 0.16 seconds\n",
      "Job ID: 50 took 0.13 seconds\n",
      "Job ID: 51 took 0.13 seconds\n",
      "Job ID: 52 took 0.14 seconds\n",
      "Job ID: 53 took 0.12 seconds\n",
      "Job ID: 54 took 0.10 seconds\n",
      "Job ID: 55 took 0.08 seconds\n",
      "Job ID: 56 took 0.06 seconds\n",
      "Job ID: 57 took 0.08 seconds\n",
      "Job ID: 58 took 0.06 seconds\n",
      "Job ID: 59 took 0.08 seconds\n",
      "Job ID: 60 took 0.10 seconds\n",
      "Job ID: 61 took 0.14 seconds\n",
      "Job ID: 62 took 0.15 seconds\n",
      "Job ID: 63 took 0.13 seconds\n",
      "Job ID: 64 took 0.12 seconds\n",
      "Job ID: 65 took 0.13 seconds\n",
      "Job ID: 66 took 0.10 seconds\n",
      "Job ID: 67 took 0.17 seconds\n",
      "Job ID: 68 took 0.11 seconds\n",
      "Job ID: 69 took 0.06 seconds\n",
      "Job ID: 70 took 0.06 seconds\n",
      "Job ID: 71 took 0.08 seconds\n",
      "Job ID: 72 took 0.08 seconds\n",
      "Job ID: 73 took 0.19 seconds\n",
      "Job ID: 74 took 0.17 seconds\n",
      "Job ID: 75 took 0.15 seconds\n",
      "Job ID: 76 took 0.13 seconds\n",
      "Job ID: 77 took 0.10 seconds\n",
      "Job ID: 78 took 0.12 seconds\n",
      "Job ID: 79 took 0.14 seconds\n",
      "Job ID: 80 took 0.13 seconds\n",
      "Job ID: 81 took 0.13 seconds\n",
      "Job ID: 82 took 0.07 seconds\n",
      "Job ID: 83 took 0.09 seconds\n",
      "Job ID: 84 took 0.06 seconds\n",
      "Job ID: 85 took 0.07 seconds\n",
      "Job ID: 86 took 0.06 seconds\n",
      "Job ID: 87 took 0.09 seconds\n",
      "Job ID: 88 took 0.12 seconds\n",
      "Job ID: 89 took 0.14 seconds\n",
      "Job ID: 90 took 0.12 seconds\n",
      "Job ID: 91 took 0.11 seconds\n",
      "Job ID: 92 took 0.10 seconds\n",
      "Job ID: 93 took 0.12 seconds\n",
      "Job ID: 94 took 0.13 seconds\n",
      "Job ID: 95 took 0.12 seconds\n",
      "Job ID: 96 took 0.13 seconds\n",
      "Job ID: 97 took 0.08 seconds\n",
      "Job ID: 98 took 0.06 seconds\n",
      "Job ID: 99 took 0.06 seconds\n",
      "Job ID: 100 took 0.06 seconds\n",
      "Job ID: 101 took 0.09 seconds\n",
      "Job ID: 102 took 0.07 seconds\n",
      "Job ID: 103 took 0.12 seconds\n",
      "Job ID: 104 took 0.09 seconds\n",
      "Job ID: 105 took 0.12 seconds\n",
      "Job ID: 106 took 0.12 seconds\n",
      "Job ID: 107 took 0.14 seconds\n",
      "Job ID: 108 took 0.12 seconds\n",
      "Job ID: 109 took 0.13 seconds\n",
      "Job ID: 110 took 0.13 seconds\n",
      "Job ID: 111 took 0.11 seconds\n",
      "Job ID: 112 took 0.11 seconds\n",
      "Job ID: 113 took 0.09 seconds\n",
      "Job ID: 114 took 0.06 seconds\n",
      "Job ID: 115 took 0.06 seconds\n",
      "Job ID: 116 took 0.06 seconds\n",
      "Job ID: 117 took 0.06 seconds\n",
      "Job ID: 118 took 0.10 seconds\n",
      "Job ID: 119 took 0.12 seconds\n",
      "[0.111, 0.112, 0.152, 0.103, 0.168, 0.134, 0.129, 0.086, 0.103, 0.09, 0.109, 0.092, 0.067, 0.142, 0.146, 0.142, 0.139, 0.148, 0.182, 0.125, 0.284, 0.09, 0.113, 0.083, 0.089, 0.136, 0.126, 0.14, 0.12, 0.16, 0.126, 0.129, 0.142, 0.118, 0.095, 0.081, 0.06, 0.079, 0.058, 0.083, 0.099, 0.139, 0.152, 0.132, 0.123, 0.128, 0.1, 0.17, 0.113, 0.058, 0.063, 0.083, 0.078, 0.188, 0.169, 0.154, 0.126, 0.101, 0.121, 0.135, 0.126, 0.13, 0.066, 0.087, 0.064, 0.072, 0.064, 0.094, 0.123, 0.14, 0.121, 0.11, 0.105, 0.122, 0.127, 0.123, 0.129, 0.079, 0.058, 0.055, 0.062, 0.089, 0.067, 0.119, 0.086, 0.121, 0.12, 0.145, 0.117, 0.13, 0.126, 0.11, 0.107, 0.088, 0.059, 0.058, 0.055, 0.059, 0.098, 0.115]\n",
      "Zeit für die Ausführung der Zelle: 27.01 seconds\n",
      "Mittelwert aller Spark Jobs: 0.11 seconds\n",
      "Median aller Spark Jobs: 0.11 seconds\n",
      "Sdt aller Spark Jobs: 0.04 seconds\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "listh100 = []\n",
    "\n",
    "start_all = time.time()\n",
    "for i in range(100):\n",
    "    dfrh= spark.read.parquet(\"hdfs:///input/parquet\")\n",
    "    app_id = requests.get(f\"{SPARK_UI}/api/v1/applications\").json()[0][\"id\"]\n",
    "    job = requests.get(f\"{SPARK_UI}/api/v1/applications/{app_id}/jobs\").json()[0]\n",
    "    start = datetime.fromisoformat(job[\"submissionTime\"].replace(\"GMT\", \"+00:00\"))\n",
    "    end = datetime.fromisoformat(job[\"completionTime\"].replace(\"GMT\", \"+00:00\"))\n",
    "    timer = (end - start).total_seconds()\n",
    "    job_info = requests.get(f\"{SPARK_UI}/api/v1/applications/{app_id}/jobs\").json()\n",
    "    latest_job = sorted(job_info, key=lambda j: j[\"submissionTime\"], reverse=True)[0]\n",
    "    listh100.append(timer)\n",
    "    print(f\"Job ID: {latest_job['jobId']} took {timer:.2f} seconds\")\n",
    "end_all = time.time()\n",
    "\n",
    "print(listh100)\n",
    "print(f\"Zeit für die Ausführung der Zelle: {end_all - start_all:.2f} seconds\")\n",
    "print(f\"Mittelwert aller Spark Jobs: {np.mean(listh100):.2f} seconds\")\n",
    "print(f\"Median aller Spark Jobs: {np.median(listh100):.2f} seconds\")\n",
    "print(f\"Sdt aller Spark Jobs: {np.std(listh100):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d06c70",
   "metadata": {},
   "source": [
    "## Count testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92e5b655",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrh= spark.read.parquet(\"hdfs:///input/parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "520ca32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrh.createOrReplaceTempView(\"my_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0f9606",
   "metadata": {},
   "source": [
    "Einfacher select und count, ohne Ausgabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25658c67-05eb-4a7f-bb03-38a3fc7f84af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Included Job 137 took 0.05s\n",
      "  Included Job 136 took 9.55s\n",
      "  Included Job 135 took 8.82s\n",
      "  Included Job 134 took 12.49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Included Job 140 took 0.05s\n",
      "  Included Job 139 took 9.49s\n",
      "  Included Job 138 took 8.40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Included Job 143 took 0.10s\n",
      "  Included Job 142 took 9.48s\n",
      "  Included Job 141 took 9.27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Included Job 146 took 0.08s\n",
      "  Included Job 145 took 9.05s\n",
      "  Included Job 144 took 7.98s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Included Job 149 took 0.03s\n",
      "  Included Job 148 took 9.24s\n",
      "  Included Job 147 took 8.47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Included Job 152 took 0.07s\n",
      "  Included Job 151 took 10.01s\n",
      "  Included Job 150 took 8.42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Included Job 155 took 0.07s\n",
      "  Included Job 154 took 8.95s\n",
      "  Included Job 153 took 7.96s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Included Job 158 took 0.07s\n",
      "  Included Job 157 took 9.71s\n",
      "  Included Job 156 took 7.68s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Included Job 161 took 0.04s\n",
      "  Included Job 160 took 9.29s\n",
      "  Included Job 159 took 9.24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Included Job 164 took 0.04s\n",
      "  Included Job 163 took 9.29s\n",
      "  Included Job 162 took 7.91s\n",
      "Average time over 10 queries: 19.13 seconds\n",
      "[30.915, 17.945, 18.855, 17.101, 17.748, 18.491, 16.986, 17.461, 18.562, 17.246]\n",
      "Zeit für die Ausführung der Zelle: 205.00 seconds\n",
      "Mittelwert aller Spark Jobs: 19.13 seconds\n",
      "Median aller Spark Jobs: 17.85 seconds\n",
      "Sdt aller Spark Jobs: 3.98 seconds\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "listcount = []\n",
    "\n",
    "start_all = time.time()\n",
    "def get_all_jobs():\n",
    "    app_id = requests.get(f\"{SPARK_UI}/api/v1/applications\").json()[0][\"id\"]\n",
    "    job_info = requests.get(f\"{SPARK_UI}/api/v1/applications/{app_id}/jobs\").json()\n",
    "    return job_info\n",
    "\n",
    "for i in range(10):\n",
    "    # Step 1: Snapshot of current jobs\n",
    "    jobs_before = {j[\"jobId\"] for j in get_all_jobs()}\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT gbifID, COUNT(gbifID) AS count\n",
    "    FROM my_table\n",
    "    WHERE gbifID IS NOT NULL\n",
    "    GROUP BY gbifID\n",
    "    ORDER BY count DESC\n",
    "\"\"\"\n",
    "\n",
    "# Create Spark DataFrame\n",
    "    spark_df = spark.sql(query)\n",
    "\n",
    "# Show the result in Spark (default top 20 rows)\n",
    "    spark_df.count()\n",
    "    \n",
    "    # Step 3: Wait to ensure Spark UI is updated\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Step 4: Get new jobs\n",
    "    jobs_after = get_all_jobs()\n",
    "    new_jobs = [j for j in jobs_after if j[\"jobId\"] not in jobs_before]\n",
    "    \n",
    "    # Step 5: Sum duration of all new jobs\n",
    "    total_duration = 0.0\n",
    "    for job in new_jobs:\n",
    "        start = datetime.fromisoformat(job[\"submissionTime\"].replace(\"GMT\", \"+00:00\"))\n",
    "        end = datetime.fromisoformat(job[\"completionTime\"].replace(\"GMT\", \"+00:00\"))\n",
    "        duration = (end - start).total_seconds()\n",
    "        total_duration += duration\n",
    "        print(f\"  Included Job {job['jobId']} took {duration:.2f}s\")\n",
    "\n",
    "    listcount.append(total_duration)\n",
    "end_all = time.time()\n",
    "# Final average\n",
    "print(\"Average time over 10 queries:\", round(math.fsum(listcount)/len(listcount), 2), \"seconds\")\n",
    "print(listcount)\n",
    "print(f\"Zeit für die Ausführung der Zelle: {end_all - start_all:.2f} seconds\")\n",
    "print(f\"Mittelwert aller Spark Jobs: {np.mean(listcount):.2f} seconds\")\n",
    "print(f\"Median aller Spark Jobs: {np.median(listcount):.2f} seconds\")\n",
    "print(f\"Sdt aller Spark Jobs: {np.std(listcount):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70a8faf-e891-42a7-9966-162979ee67cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
